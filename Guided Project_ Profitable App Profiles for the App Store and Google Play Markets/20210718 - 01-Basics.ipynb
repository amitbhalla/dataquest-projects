{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App store market analysis (Amit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project performs several analysis on Apple and Google's app stores to understand the market of free apps. It also sizes them to understand which kind of apps make the most sense to invest in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==== Data ====\n",
    "\n",
    "We work on data provided to us on:\n",
    "1. Apple app store in 'AppleStore.csv'(Source: [Mobile App Store](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps))\n",
    "2. Google play store in 'googleplaystore.csv' (Source: [Google Play Store Apps](https://www.kaggle.com/lava18/google-play-store-apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==== All import statements ===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==== All functions ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `explore_data` allows the user to explore any specific rows of dataset. (Optional) It also let's the user get the count of rows and columns. There is no return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset_slice[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `open_dataset` allows users to open a dataset and returns the dataset as a **list**. (Optional) Idicate if there is a header. If indicated, the function will not return it. If you want the header indicate `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_dataset(csv_name, header=False):\n",
    "    open_file = open(csv_name, encoding='utf8')\n",
    "    read_file = reader(open_file)\n",
    "    all_data = list(read_file)\n",
    "    \n",
    "    if header:\n",
    "        all_data = all_data[1:]\n",
    "        \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `missing_data_rows` compares length of each row in data with the length of header and if the length is smaller it returns their index in a list. (Optional) You can ask the function to delete these rows from dataset. In this case we also return the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_rows(dataset, delete=False):\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    index_list = []\n",
    "    recombined_data = []\n",
    "    \n",
    "    for row in rows:\n",
    "        if len(header) != len(row):\n",
    "            index_list.append(rows.index(row))\n",
    "            if delete:\n",
    "                del rows[rows.index(row)]\n",
    "    if delete:\n",
    "        # Do not forget to recombine header with rows. Header will\n",
    "        # also need to become a list of list, since rows is one\n",
    "        recombined_data = [header] + rows\n",
    "        return index_list, recombined_data\n",
    "    \n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `duplicate_data` compares column_to_check for duplicates and returns a list of indexes with a dict object as details of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate_data(dataset, column_to_check):\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    col_dict = {}\n",
    "    index_list = []\n",
    "    \n",
    "    # Create a frequency table of items\n",
    "    for row in rows:\n",
    "        if row[column_to_check] not in col_dict:\n",
    "            col_dict[row[column_to_check]] = 1\n",
    "        else:\n",
    "            col_dict[row[column_to_check]] += 1\n",
    "            index_list.append(rows.index(row))\n",
    "\n",
    "    # remove non duplicates from dictionary\n",
    "    # we need to make a copy of col_dict because when we use pop\n",
    "    # while looping it causes an error\n",
    "    # we will pop from return_dict but loop from col\n",
    "    return_dict = copy.deepcopy(col_dict)\n",
    "    for x in col_dict:\n",
    "        if col_dict[x] == 1:\n",
    "            return_dict.pop(x)\n",
    "            \n",
    "    return index_list, return_dict  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `delete_duplicate_rows` will delete duplicates (If we examine the rows we identified as duplicates, the main difference happens on the fourth column of each row, which corresponds to the number of reviews. The different numbers show that the data was collected at different times. We can use this to build a criterion for keeping rows. We won't remove rows randomly, but rather we'll keep the rows that have the highest number of reviews because the higher the number of reviews, the more reliable the ratings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_duplicate_rows(dataset, col_to_check, review_col):\n",
    "    new_dataset=[]\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    review_dict = {}\n",
    "    index_list = []\n",
    "    \n",
    "    # Create a frequency table of items\n",
    "    for row in rows:\n",
    "        if row[col_to_check] not in review_dict:\n",
    "            review_dict[row[col_to_check]] = float(row[review_col])\n",
    "        elif row[col_to_check] in review_dict:\n",
    "             if float(review_dict[row[col_to_check]]) < float(row[review_col]):\n",
    "                    review_dict[row[col_to_check]] = float(row[review_col])\n",
    "    \n",
    "    # dump rows into new_dataset\n",
    "    new_dataset = [header]\n",
    "        \n",
    "    for row in rows:        \n",
    "        if row[col_to_check] not in review_dict:\n",
    "            new_dataset.append(row)\n",
    "        else:\n",
    "            # Check if this is the heighest reviews\n",
    "            if float(row[review_col]) == review_dict[row[col_to_check]]:\n",
    "                # since there are duplicate rows of same reviews\n",
    "                # we need to do this once only\n",
    "                # we have to extract names in the list of list\n",
    "                # and check if name is in it\n",
    "                chk_list = []\n",
    "                for item in new_dataset:\n",
    "                    chk_list.append(item[0])\n",
    "                    \n",
    "                # short cut for writing above three lines in one line\n",
    "                # chk_list = [item[0] for item in new_dataset] \n",
    "                \n",
    "                if row[col_to_check] not in chk_list:\n",
    "                    new_dataset.append(row)\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `check_non_english` returns apps with charachters where `ord()` value is not between `0` and `127`. It expects these to be forigen language apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_non_english(dataset, name_column):\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    \n",
    "    non_eng_dict = {}\n",
    "    \n",
    "    for row in rows:\n",
    "        for char in row[name_column]:\n",
    "            if (0 < ord(char) > 127):\n",
    "                if row[name_column] not in non_eng_dict:\n",
    "                    non_eng_dict[row[name_column]] = 1\n",
    "                if row[name_column] in non_eng_dict:\n",
    "                    non_eng_dict[row[name_column]] += 1\n",
    "    \n",
    "    return_dict = copy.deepcopy(non_eng_dict)\n",
    "    \n",
    "    for name in non_eng_dict:\n",
    "        # Since English apps use Emojis etc, we want to save data\n",
    "        # we are deleting apps which have more than 3 chars with\n",
    "        # ord values not between 0 to 127\n",
    "        if non_eng_dict[name] < 4:\n",
    "            return_dict.pop(name)\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `delete_non_english` deletes non-english apps from the dataset and returns a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_non_english(dataset, name_column):\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    \n",
    "    non_eng_dict = {}\n",
    "    english_duct = {}\n",
    "    \n",
    "    new_dataset = [header]\n",
    "    \n",
    "    for row in rows:\n",
    "        # put in non-english\n",
    "        for char in row[name_column]:\n",
    "            if (0 < ord(char) > 127):\n",
    "                if row[name_column] not in non_eng_dict:\n",
    "                    non_eng_dict[row[name_column]] = 1\n",
    "                if row[name_column] in non_eng_dict:\n",
    "                    non_eng_dict[row[name_column]] += 1\n",
    "        # put in english if frequency < 4\n",
    "        # append if not found\n",
    "        if row[name_column] not in non_eng_dict:\n",
    "            new_dataset.append(row)\n",
    "        elif row[name_column] in non_eng_dict:\n",
    "            if non_eng_dict[row[name_column]] < 4:\n",
    "                new_dataset.append(row)\n",
    "            \n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `check_paid_apps` returns the list of paid apps, which will be deleted from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_paid_apps(dataset, name_col, price_col):\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    \n",
    "    paid_apps_dict = {}\n",
    "    \n",
    "    for row in rows:\n",
    "        if price_col == 4:\n",
    "            # treatment of apple (their column doesn't have $ in string)\n",
    "            if float(row[price_col]) != 0.0:\n",
    "                if row[name_col] not in paid_apps_dict:\n",
    "                    paid_apps_dict[row[name_col]] = float(row[price_col])\n",
    "        elif price_col == 7:\n",
    "            # treatment for Google (the price col has $ in the string)\n",
    "            price = float(row[price_col].replace('$',''))\n",
    "            if float(price) > 0.0:\n",
    "                if row[name_col] not in paid_apps_dict:\n",
    "                    paid_apps_dict[row[name_col]] = float(price)\n",
    "            \n",
    "    \n",
    "    return paid_apps_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `delete_paid_apps` deletes paid apps from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_paid_apps(dataset, name_col, price_col):\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    \n",
    "    new_dataset = []\n",
    "    new_rows = []\n",
    "    for row in rows:\n",
    "        if price_col == 4:\n",
    "            # treatment of apple (their column doesn't have $ in string)\n",
    "            if float(row[price_col]) == 0.0 or row[price_col] is None:\n",
    "                new_rows.append(row)\n",
    "                \n",
    "        elif price_col == 7:\n",
    "            # treatment for Google (the price col has $ in the string)\n",
    "            price = float(row[price_col].replace('$',''))\n",
    "            if float(price) == 0.0 or price is None:\n",
    "                new_rows.append(row)\n",
    "\n",
    "    new_dataset = [header] + new_rows \n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `gen_fq_table` generates a dictionary object with % of frequency of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fq_table(dataset, column_index):\n",
    "    header = dataset[0]\n",
    "    rows = dataset[1:]\n",
    "    fq_dict = {}\n",
    "    \n",
    "    for row in rows:\n",
    "        if row[column_index] not in fq_dict:\n",
    "            fq_dict[row[column_index]] = 1\n",
    "        else:\n",
    "            fq_dict[row[column_index]] += 1\n",
    "    \n",
    "    for item in fq_dict:\n",
    "        fq_dict[item] = round(((fq_dict[item] / len(rows)) * 100),2) \n",
    "    \n",
    "    sorted_dict = display_table(fq_dict)\n",
    "    \n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `display_table` sorts a dictionary and returns a tuple. It also flips the keys and values, i.e. Values take first columns and Keys take the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(dict_to_sort):\n",
    "    # Optional sort by frequency\n",
    "    table_display = []\n",
    "    for key in dict_to_sort:\n",
    "        key_val_as_tuple = (dict_to_sort[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "        \n",
    "    sorted_dict = sorted(table_display, reverse=True)   \n",
    "    #sorted_dict = sorted(fq_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==== Execution code ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 -> Testing file open, and exploring the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7198\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "# Apple\n",
    "apple_file = 'AppleStore.csv'\n",
    "\n",
    "apple_data = open_dataset(apple_file, False)\n",
    "explore_data(apple_data, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10842\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "# Google\n",
    "google_file = 'googleplaystore.csv'\n",
    "\n",
    "google_data = open_dataset(google_file, False)\n",
    "explore_data(google_data, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 -> Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Rows with missing entries or errors**\n",
    "2. Remove duplicates\n",
    "3. Remove non-english apps\n",
    "4. Isolate free apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix Apple data\n",
    "apple_error_index = missing_data_rows(apple_data, delete=False)\n",
    "apple_error_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(apple_error_index) > 0:\n",
    "    apple_error_index, apple_data = missing_data_rows(apple_data, delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10472]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix Google data\n",
    "google_error_index = missing_data_rows(google_data, delete=False)\n",
    "google_error_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(google_error_index) > 0:\n",
    "    google_error_index, google_data = missing_data_rows(google_data, delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Data: 7198\n",
      "Google Data: 10841\n"
     ]
    }
   ],
   "source": [
    "print('Apple Data:', len(apple_data))\n",
    "print('Google Data:', len(google_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 -> Data cleaning (contd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rows with missing entries or errors\n",
    "2. **Remove duplicates**\n",
    "3. Remove non-english apps\n",
    "4. Isolate free apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_duplicate_index, apple_duplicate_dict = check_duplicate_data (apple_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicate(s) found\n"
     ]
    }
   ],
   "source": [
    "print(len(apple_duplicate_index), 'duplicate(s) found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_duplicate_index, google_duplicate_dict = check_duplicate_data (google_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181 duplicate(s) found\n"
     ]
    }
   ],
   "source": [
    "print(len(google_duplicate_index), 'duplicate(s) found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start removing duplicates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple's duplicates are in `0` and reviews are in `5` column. This is the column we will use to determine which duplicate rows to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_nodups_data = delete_duplicate_rows(apple_data, 0, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Apple data length: 7198\n",
      "Identified duplicates were: 0\n",
      "New Apple data length: 7198\n"
     ]
    }
   ],
   "source": [
    "print('Original Apple data length:', len(apple_data))\n",
    "print('Identified duplicates were:', len(apple_duplicate_index))\n",
    "print('New Apple data length:', len(apple_nodups_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7198\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(apple_nodups_data, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google's duplicates are in `0` and reviews are in `3` column. This is the column we will use to determine which duplicate rows to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_nodups_data = delete_duplicate_rows(google_data, 0, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Google data length: 10841\n",
      "Identified duplicates were: 1181\n",
      "New Google data length: 9660\n"
     ]
    }
   ],
   "source": [
    "print('Original Google data length:', len(google_data))\n",
    "print('Identified duplicates were:', len(google_duplicate_index))\n",
    "print('New Google data length:', len(google_nodups_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 9660\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(google_nodups_data, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 -> Data cleaning (contd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rows with missing entries or errors\n",
    "2. Remove duplicates\n",
    "3. **Remove non-english apps**\n",
    "4. Isolate free apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Info:** The numbers corresponding to the characters we commonly use in an English text are all in the range 0 to 127, according to the ASCII (American Standard Code for Information Interchange) system. Based on this number range, we can build a function that detects whether a character belongs to the set of common English characters or not. If the number is equal to or less than 127, then the character belongs to the set of common English characters.\n",
    "\n",
    "If an app name contains a character that is greater than 127, then it probably means that the app has a non-English name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple app names are in `1` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_non_english = check_non_english(apple_nodups_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042 Suspected non-english app(s) found\n"
     ]
    }
   ],
   "source": [
    "print(len(apple_non_english), 'Suspected non-english app(s) found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google app names are in `0` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_non_english = check_non_english(google_nodups_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 Suspected non-english app(s) found\n"
     ]
    }
   ],
   "source": [
    "print(len(google_non_english), 'Suspected non-english app(s) found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start removing non-english apps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_english_nodupes = delete_non_english(apple_nodups_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Apple data length: 7198\n",
      "Identified non-english were: 1042\n",
      "New Apple data length: 6156\n"
     ]
    }
   ],
   "source": [
    "print('Original Apple data length:', len(apple_nodups_data))\n",
    "print('Identified non-english were:', len(apple_non_english))\n",
    "print('New Apple data length:', len(apple_english_nodupes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 6156\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(apple_english_nodupes, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_english_nodupes = delete_non_english(google_nodups_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Google data length: 9660\n",
      "Identified non-english were: 62\n",
      "New Google data length: 9598\n"
     ]
    }
   ],
   "source": [
    "print('Original Google data length:', len(google_nodups_data))\n",
    "print('Identified non-english were:', len(google_non_english))\n",
    "print('New Google data length:', len(google_english_nodupes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 9598\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(google_english_nodupes, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 -> Data cleaning (contd.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rows with missing entries or errors\n",
    "2. Remove duplicates\n",
    "3. Remove non-english apps\n",
    "4. **Isolate free apps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple has name in `1` price in `4` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_paid_apps = check_paid_apps(apple_english_nodupes, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2952 Paid app(s) found\n"
     ]
    }
   ],
   "source": [
    "print(len(apple_paid_apps), 'Paid app(s) found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google has name in `0` price in `7` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_paid_apps = check_paid_apps(google_english_nodupes, 0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "749 Paid app(s) found\n"
     ]
    }
   ],
   "source": [
    "print(len(google_paid_apps), 'Paid app(s) found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start removing paid apps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apple_free_appdata = delete_paid_apps(apple_english_nodupes, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Apple data length: 6156\n",
      "Identified paid were: 2952\n",
      "New Apple data length: 3204\n"
     ]
    }
   ],
   "source": [
    "print('Original Apple data length:', len(apple_english_nodupes))\n",
    "print('Identified paid were:', len(apple_paid_apps))\n",
    "print('New Apple data length:', len(apple_free_appdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 3204\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(apple_free_appdata, 0, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_free_appdata = delete_paid_apps(google_english_nodupes, 0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Google data length: 9598\n",
      "Identified paid were: 749\n",
      "New Google data length: 8849\n"
     ]
    }
   ],
   "source": [
    "print('Original Google data length:', len(google_english_nodupes))\n",
    "print('Identified paid were:', len(google_paid_apps))\n",
    "print('New Google data length:', len(google_free_appdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 8849\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(google_free_appdata, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 -> Analysis start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned in the introduction, our goal is to determine the kinds of apps that are likely to attract more users because the number of people using our apps affect our revenue.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea has three steps:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we develop it further.\n",
    "3. If the app is profitable after six months, we build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "Because our end goal is to add the app on both Google Play and the App Store, we need to find app profiles that are successful in both markets. For instance, a profile that works well for both markets might be a productivity app that makes use of gamification.\n",
    "\n",
    "Let's begin the analysis by determining the most common genres for each market. For this, we'll need to build frequency tables for a few columns in our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Analysis of most common genres in each market**\n",
    "\n",
    "\n",
    "|Store|column_name|Index|\n",
    "|------|------|------|\n",
    "|Apple|prime_genre|`11`|\n",
    "|Google|Category|`1`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze the frequency table you generated for the prime_genre column of the App Store dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **What is the most common genre? What is the next most common?**\n",
    "2. What other patterns do you see?\n",
    "3. What is the general impression — are most of the apps designed for practical purposes (education, shopping, utilities, productivity, lifestyle) or more for entertainment (games, photo and video, social networking, sports, music)?\n",
    "4. Can you recommend an app profile for the App Store market based on this frequency table alone? If there's a large number of apps for a particular genre, does that also imply that apps of that genre generally have a large number of users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58.26, 'Games')\n",
      "(7.84, 'Entertainment')\n",
      "(5.0, 'Photo & Video')\n",
      "(3.68, 'Education')\n",
      "(3.31, 'Social Networking')\n"
     ]
    }
   ],
   "source": [
    "apple_analysis1 = gen_fq_table(apple_free_appdata, 11)\n",
    "print(apple_analysis1[0])\n",
    "print(apple_analysis1[1])\n",
    "print(apple_analysis1[2])\n",
    "print(apple_analysis1[3])\n",
    "print(apple_analysis1[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the most common genre? What is the next most common?\n",
    "2. **What other patterns do you see?**\n",
    "3. What is the general impression — are most of the apps designed for practical purposes (education, shopping, utilities, productivity, lifestyle) or more for entertainment (games, photo and video, social networking, sports, music)?\n",
    "4. Can you recommend an app profile for the App Store market based on this frequency table alone? If there's a large number of apps for a particular genre, does that also imply that apps of that genre generally have a large number of users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyze the frequency table you generated for the Category and Genres column of the Google Play dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **What are the most common genres?**\n",
    "2. What other patterns do you see?\n",
    "3. Compare the patterns you see for the Google Play market with those you saw for the App Store market.\n",
    "4. Can you recommend an app profile based on what you found so far? Do the frequency tables you generated reveal the most frequent app genres or what genres have the most users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
